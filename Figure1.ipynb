{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-aquarium",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import math\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.stats import ranksums\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from scipy.stats.mstats import kruskalwallis\n",
    "import matplotlib as mlt\n",
    "import matplotlib.lines as mlines\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from numpy.random import randn\n",
    "from numpy.random import seed\n",
    "from numpy import mean\n",
    "from numpy import var\n",
    "\n",
    "from matplotlib import cm\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms as mtransforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309a073c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pvalue(data1, data2, freq_vals): \n",
    "    \n",
    "    pvalue = np.zeros(len(freq_vals))\n",
    "    \n",
    "    for iF in range(len(freq_vals)):\n",
    "        _, pvalue[iF] = ranksums(data1[:,iF], data2[:,iF])\n",
    "    \n",
    "    freq_uncorrected = freq_vals[pvalue < 0.05]\n",
    "        \n",
    "    _, pvals_corrected, _, _ = multipletests(pvalue, method='fdr_bh')\n",
    "    \n",
    "    freq_corrected = freq_vals[pvals_corrected < 0.05]\n",
    "        \n",
    "    return freq_uncorrected, freq_corrected, pvalue, pvals_corrected\n",
    "    \n",
    "def compute_bootstraped_percentile(data, nTrials):\n",
    "    nSubj, nFreqs = data.shape\n",
    "    bootMat = np.zeros((nFreqs, nTrials))\n",
    "    for i_trials in range(nTrials):\n",
    "        idx_subj = np.random.randint(0,nSubj,nSubj)\n",
    "        bootMat[:,i_trials] = np.nanmean(data[idx_subj,:], axis=0)\n",
    "    return np.percentile(bootMat, (2.5,97.5), axis=1)\n",
    "\n",
    "def plot_curve(ax, freq_vals, data, color, ls, label, a_size=6, alpha=1):\n",
    "            \n",
    "    def compute_bootstraped_percentile(data, nTrials):\n",
    "        nSubj, nFreqs = data.shape\n",
    "        bootMat = np.zeros((nFreqs, nTrials))\n",
    "        for i_trials in range(nTrials):\n",
    "            idx_subj = np.random.randint(0,nSubj,nSubj)\n",
    "            bootMat[:,i_trials] = np.nanmean(data[idx_subj,:], axis=0)\n",
    "        return np.percentile(bootMat, (2.5,97.5), axis=1)\n",
    "    \n",
    "    perc = compute_bootstraped_percentile(data,1000)\n",
    "    \n",
    "    ax.fill_between(freq_vals, perc[0,...], perc[1,...], alpha=0.1, color=color)\n",
    "    \n",
    "    ax.semilogx(freq_vals, data.mean(axis=0), color=color, label=label, linestyle=ls)\n",
    "\n",
    "    ax.tick_params(labelsize=a_size)\n",
    "\n",
    "def plot_stats(ax, freq, freq_corr, pos, color='black', marker='o', m_size=6):\n",
    "    for xc in freq:\n",
    "        ax.scatter(xc, pos, s=m_size, marker=marker, edgecolors=color, facecolors='none')\n",
    "    \n",
    "    for xc in freq_corr:\n",
    "        ax.scatter(xc, pos, s=m_size, marker=marker,  edgecolors=color, facecolors=color)\n",
    "        \n",
    "def cohend(d1, d2, type='rm'):\n",
    "    # calculate the size of samples\n",
    "    n1, n2 = len(d1), len(d2)\n",
    "    # calculate the variance of the samples\n",
    "    s1, s2 = var(d1, ddof=1), var(d2, ddof=1)\n",
    "    # calculate the pooled standard deviation\n",
    "    if type=='rm':\n",
    "        difference = d1 - d2\n",
    "        s = np.std(difference)\n",
    "    else:\n",
    "        s = np.sqrt(((n1 - 1) * s1 + (n2 - 1) * s2) / (n1 + n2 - 2))\n",
    "            \n",
    "    # calculate the means of the samples\n",
    "    u1, u2 = mean(d1), mean(d2)\n",
    "    # calculate the effect size\n",
    "    return (u1 - u2) / s\n",
    "\n",
    "def plot_cohen(ax, freq, stats, pos, color='black'):\n",
    "\n",
    "    for idxd, d in enumerate(stats):\n",
    "        \n",
    "        if d > 0.8: # large effect\n",
    "            \n",
    "            ax.scatter(freq[idxd], pos, marker='s', edgecolors=color, facecolors='none')\n",
    "            \n",
    "        if d > 0.5: # medium effect\n",
    "            \n",
    "            ax.scatter(freq[idxd], pos, marker='s', edgecolors=color, facecolors='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017594a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_frequency_axis(f_min=2, f_max= 4, num_wavelet = 10):\n",
    "\n",
    "    f_min_log = math.floor(np.log10(f_min))\n",
    "    f_max_log = math.ceil(np.log10(f_max))\n",
    "    mb = np.logspace(f_min_log, f_max_log, num=num_wavelet) # Morlet bank \n",
    "    freq_vals = mb[(2.1 < mb) & (mb < 90)] # Frequency of interest\n",
    "    \n",
    "    freq_labels = [('%.2f'%x) for x in freq_vals]\n",
    "    \n",
    "    return freq_vals, freq_labels\n",
    "    \n",
    "def extract_fei_new(files):\n",
    "    \n",
    "    name_subjs, data_masked = list(), list()\n",
    "    for _, file in enumerate(tqdm(files)):\n",
    "        \n",
    "        name_subjs.append(file.split('/')[9][:6])\n",
    "        \n",
    "        tmp = np.load(file, allow_pickle=True)\n",
    "\n",
    "        data_masked.append(np.nanmean(tmp[1,...],axis=0)) # tmp[1] == rimuovo fEI dove DFA < 0.6\n",
    "    \n",
    "    fEI_masked = np.array(data_masked)\n",
    "\n",
    "    return name_subjs, fEI_masked\n",
    "\n",
    "def extract_bis_new(files):\n",
    "    \n",
    "    data, name_subjs = list(), list()\n",
    "    for ifile, file in enumerate(tqdm(files)):\n",
    "        \n",
    "        name_subjs.append(file.split('/')[9][:6])\n",
    "        \n",
    "        tmp = np.load(file, allow_pickle=True)\n",
    "        \n",
    "        data.append(np.mean(tmp,axis=0)) # Average channels\n",
    "    \n",
    "    bis = np.array(data)\n",
    "    return name_subjs, bis\n",
    "\n",
    "def extract_dfa_new(files):\n",
    "    \n",
    "    dfa, name_subjs = list(), list()\n",
    "    for ifile, file in enumerate(tqdm(files)):\n",
    "      \n",
    "        name_subjs.append(file.split('/')[9][:6])\n",
    "        datafile = np.load(file, allow_pickle=True)\n",
    "        data = datafile.item()\n",
    "        data_dfa = data['DFA']\n",
    "        dfa.append(np.nanmean(data_dfa,axis=0))\n",
    "    \n",
    "    dfa = np.array(dfa)\n",
    "    return name_subjs, dfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perceived-morris",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbd_root = '.../RBD_root/'\n",
    "ctrl_root = '.../Control_root/'\n",
    "path_out = '.../Results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-sucking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set frequency limits\n",
    "f_min = 2\n",
    "f_max = 90\n",
    "scale_freq='log'\n",
    "\n",
    "freq_vals, _ = create_frequency_axis(f_max=f_max, f_min=f_min, scale_freq=scale_freq)\n",
    "freq_vals = freq_vals[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e733277c",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_subj_r1, dfa_r1 = extract_dfa_new(sorted(glob.glob(os.path.join(rbd_root + 'dfa/run-01/','sub*'))))\n",
    "_, dfa_C = extract_dfa_new(sorted(glob.glob(os.path.join(rbd_root + 'dfa/ctrl/','sub*'))))\n",
    "\n",
    "_, fei_r1 = extract_fei_new(sorted(glob.glob(os.path.join(rbd_root + 'fei/run-01/','*fei06*'))))\n",
    "_, fei_C = extract_fei_new(sorted(glob.glob(os.path.join(rbd_root + 'fei/ctrl/','*fei06*'))))\n",
    "\n",
    "_, bis_r1 = extract_bis_new(sorted(glob.glob(os.path.join(rbd_root + 'bis/run-01/','sub*'))))\n",
    "_, bis_C = extract_bis_new(sorted(glob.glob(os.path.join(rbd_root + 'bis/ctrl/','sub*'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9d0327",
   "metadata": {},
   "source": [
    "#### Compute confidence interval (bootstrap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40dbb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_dfa_r1 = compute_bootstraped_percentile(dfa_r1[:,:30],1000)\n",
    "perc_dfa_C = compute_bootstraped_percentile(dfa_C[:,:30],1000)\n",
    "\n",
    "perc_bis_r1 = compute_bootstraped_percentile(bis_r1[:,:30],1000)\n",
    "perc_bis_C = compute_bootstraped_percentile(bis_C[:,:30],1000)\n",
    "\n",
    "perc_fei_r1 = compute_bootstraped_percentile(fei_r1[:,:30],1000)\n",
    "perc_fei_C = compute_bootstraped_percentile(fei_C[:,:30],1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1012a1b",
   "metadata": {},
   "source": [
    "#### Wilcoxon to test difference between groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c24f29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dfa_r1c, freq_dfa_r1c_corrected, pdfa, p_Corr_dfa = compute_pvalue(dfa_r1, dfa_C, freq_vals)\n",
    "\n",
    "freq_bis_r1c, freq_bis_r1c_corrected, pbis, p_Corr_bis = compute_pvalue(bis_r1, bis_C, freq_vals)\n",
    "\n",
    "freq_fei_r1c, freq_fei_r1c_corrected, pfei, p_Corr_fei = compute_pvalue(fei_r1, fei_C, freq_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4e2854",
   "metadata": {},
   "source": [
    "#### Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69db6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Panels \n",
    "fig = plt.figure(figsize=(17.6/2.54, 6/2.54), layout='constrained')\n",
    "\n",
    "gs = fig.add_gridspec(nrows=3, ncols=3)\n",
    "\n",
    "ax1 = fig.add_subplot(gs[:-1, 0])\n",
    "ax2 = fig.add_subplot(gs[:-1, 1])\n",
    "ax3 = fig.add_subplot(gs[:-1, 2])\n",
    "\n",
    "ax4 = fig.add_subplot(gs[-1, 0])\n",
    "ax5 = fig.add_subplot(gs[-1, 1])\n",
    "ax6 = fig.add_subplot(gs[-1, 2])\n",
    "\n",
    "a_size=6\n",
    "l_size=8\n",
    "m_size=6\n",
    "\n",
    "# Axis 1\n",
    "plot_curve(ax1, freq_vals, dfa_r1[:,:30], 'blue', '-', 'iRBD - baseline')\n",
    "plot_curve(ax1, freq_vals, dfa_C[:,:30], 'grey', '-', 'HC')\n",
    "plot_stats(ax1, freq_dfa_r1c, freq_dfa_r1c_corrected, .875)\n",
    "ax1.set_ylim([.55, .9])\n",
    "ax1.set_ylabel('DFA', fontsize=l_size)\n",
    "\n",
    "\n",
    "# Axis 2\n",
    "plot_curve(ax2, freq_vals, bis_r1[:,:30], 'blue', '-', 'iRBD - baseline')\n",
    "plot_curve(ax2, freq_vals, bis_C[:,:30], 'grey', '-', 'HC')\n",
    "plot_stats(ax2, freq_bis_r1c, freq_bis_r1c_corrected, 4.75)\n",
    "ax2.set_ylim([2, 5])\n",
    "ax2.set_ylabel('BiS', fontsize=l_size)\n",
    "\n",
    "# Axis 3\n",
    "plot_curve(ax3, freq_vals, fei_r1[:,:30], 'blue', '-', 'iRBD - baseline')\n",
    "plot_curve(ax3, freq_vals, fei_C[:,:30], 'grey', '-', 'HC')\n",
    "plot_stats(ax3, freq_fei_r1c, freq_fei_r1c_corrected, 1.075)\n",
    "ax3.set_ylim([.7, 1.1])\n",
    "ax3.set_ylabel('fEI', fontsize=l_size)\n",
    "\n",
    "ax1.spines['right'].set_visible(False)\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax2.spines['right'].set_visible(False)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax3.spines['right'].set_visible(False)\n",
    "ax3.spines['top'].set_visible(False)\n",
    "\n",
    "ax3.legend(loc='lower right', fontsize=a_size, frameon=False)\n",
    "\n",
    "# Cohen's d\n",
    "d_bis = list()\n",
    "d_fei = list()\n",
    "d_dfa = list()\n",
    "\n",
    "for iF in range(len(freq_vals)):\n",
    "\n",
    "    d_bis.append(cohend(bis_r1[:,iF], bis_C[:,iF], None))\n",
    "    d_fei.append(cohend(fei_r1[:,iF], fei_C[:,iF], None))\n",
    "    d_dfa.append(cohend(dfa_r1[:,iF], dfa_C[:,iF], None))\n",
    "    \n",
    "    \n",
    "d_dfa = np.asarray(d_dfa)\n",
    "d_bis = np.asarray(d_bis)\n",
    "d_fei = np.asarray(d_fei)\n",
    "\n",
    "# Axis 4\n",
    "ax4.semilogx(freq_vals, d_dfa, color='black')\n",
    "ax4.semilogx(freq_vals, d_dfa, color='black')\n",
    "ax5.semilogx(freq_vals, d_bis, color='black')\n",
    "ax5.semilogx(freq_vals, d_bis, color='black')\n",
    "ax6.semilogx(freq_vals, d_fei, color='black')\n",
    "ax6.semilogx(freq_vals, d_fei,color='black')\n",
    "\n",
    "ax4.fill_between(freq_vals, 1.5, -1, where=(d_dfa > .5), alpha=0.2, color='black')\n",
    "ax5.fill_between(freq_vals, 1.5, -1, where=(d_bis > .5), alpha=0.2, color='black')\n",
    "ax6.fill_between(freq_vals, 1.5, -1, where=(d_fei > .5), alpha=0.2, color='black')\n",
    "\n",
    "ax4.spines['right'].set_visible(False)\n",
    "ax4.spines['top'].set_visible(False)\n",
    "ax5.spines['right'].set_visible(False)\n",
    "ax5.spines['top'].set_visible(False)\n",
    "ax6.spines['right'].set_visible(False)\n",
    "ax6.spines['top'].set_visible(False)\n",
    "\n",
    "ax4.set_yticks([-1, 0, 1])\n",
    "ax5.set_yticks([-1, 0, 1])\n",
    "ax6.set_yticks([-1, 0, 1])\n",
    "\n",
    "ax1.set_xticks([], [])\n",
    "ax2.set_xticks([], [])\n",
    "ax3.set_xticks([], [])\n",
    "ax4.set_xticks([2,5,10,20,50,70], [2,5,10,20,50,70])\n",
    "ax5.set_xticks([2,5,10,20,50,70], [2,5,10,20,50,70])\n",
    "ax6.set_xticks([2,5,10,20,50,70], [2,5,10,20,50,70])\n",
    "\n",
    "ax4.tick_params(labelsize=a_size)\n",
    "ax5.tick_params(labelsize=a_size)\n",
    "ax6.tick_params(labelsize=a_size)\n",
    "\n",
    "ax4.set_xlabel('Frequencies [Hz]', fontsize=l_size)\n",
    "ax5.set_xlabel('Frequencies [Hz]', fontsize=l_size)\n",
    "ax6.set_xlabel('Frequencies [Hz]', fontsize=l_size)\n",
    "ax4.set_ylabel(\"Cohen's d\", fontsize=l_size)\n",
    "\n",
    "fig.align_ylabels([(ax1,ax2,ax3),(ax4,ax5,ax5)])\n",
    "plt.savefig(path_out + 'Crit_F2.svg', dpi=600, bbox_inches = \"tight\")\n",
    "plt.savefig(path_out + 'Crit_F2.png', dpi=600, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9ebbf7-788f-4682-99a2-f98034ba97e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df_dfa = pd.DataFrame()\n",
    "df_dfa['Frequencies [Hz]'] = freq_vals\n",
    "df_dfa['$\\it{p}$'] = pdfa\n",
    "df_dfa['$\\it{p}$ corrected'] =  p_Corr_dfa\n",
    "\n",
    "df_bis = pd.DataFrame()\n",
    "df_bis['Frequencies [Hz]'] = freq_vals\n",
    "df_bis['$\\it{p}$'] = pbis\n",
    "df_bis['$\\it{p}$ corrected'] =  p_Corr_bis\n",
    "\n",
    "df_fei = pd.DataFrame()\n",
    "df_fei['Frequencies [Hz]'] = freq_vals\n",
    "df_fei['$\\it{p}$'] = pfei\n",
    "df_fei['$\\it{p}$ corrected'] = p_Corr_fei\n",
    "\n",
    "with pd.ExcelWriter('SupplementaryTables_F3.xlsx') as writer:\n",
    "    df_dfa.set_index('Frequencies [Hz]').to_excel(writer, sheet_name='Figure3A')\n",
    "    df_bis.set_index('Frequencies [Hz]').to_excel(writer, sheet_name='Figure3C')\n",
    "    df_fei.set_index('Frequencies [Hz]').to_excel(writer, sheet_name='Figure3D')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
